{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 529,
   "id": "323d0dd6-5110-4224-bfab-345f95bc321a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch #may take some times\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "id": "8e8da551-e5f5-4236-9a70-316df9530a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"./fine_tuned_bengali_model\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./fine_tuned_bengali_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "id": "2b3c33c2-82c4-46a4-9673-331eecae4145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 1\n"
     ]
    }
   ],
   "source": [
    "input_text = \"১ম প্রকাশ\"\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "outputs = model(**inputs)\n",
    "predictions = torch.argmax(outputs.logits, dim=1)\n",
    "print(f\"Prediction: {predictions.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "id": "633d8ecb-136f-41dc-a33b-40029868b6c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-docx in c:\\users\\minha\\anaconda3\\lib\\site-packages (1.1.2)\n",
      "Requirement already satisfied: lxml>=3.1.0 in c:\\users\\minha\\anaconda3\\lib\\site-packages (from python-docx) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=4.9.0 in c:\\users\\minha\\anaconda3\\lib\\site-packages (from python-docx) (4.11.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install python-docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "id": "f568b6a6-e659-4be2-bd2f-765886aa810e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "id": "6bb766eb-0b8a-4186-afd1-fbb64207a628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: reportlab in c:\\users\\minha\\anaconda3\\lib\\site-packages (4.2.5)\n",
      "Requirement already satisfied: pillow>=9.0.0 in c:\\users\\minha\\anaconda3\\lib\\site-packages (from reportlab) (10.4.0)\n",
      "Requirement already satisfied: chardet in c:\\users\\minha\\anaconda3\\lib\\site-packages (from reportlab) (4.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install reportlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "id": "ccafdf2a-bc65-40d0-bf3e-ce0ce178f259",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "id": "473a727e-6c38-4ed0-af7a-cd0e00519b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: unicodeconverter in c:\\users\\minha\\anaconda3\\lib\\site-packages (0.1.0b12)\n"
     ]
    }
   ],
   "source": [
    "!pip install unicodeconverter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "id": "70663faf-9447-4f0e-ae96-d86070aec3a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langid in c:\\users\\minha\\anaconda3\\lib\\site-packages (1.1.6)\n",
      "Requirement already satisfied: numpy in c:\\users\\minha\\anaconda3\\lib\\site-packages (from langid) (1.26.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install langid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "id": "50293bdb-a7d5-4747-a032-3aadb70654d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodeconverter as uc\n",
    "def unicoded_text(bijoy_text):\n",
    "  unicode_text = uc.convert_bijoy_to_unicode(bijoy_text)\n",
    "  return unicode_text\n",
    "\n",
    "def reverse_unicode(unicode_text):\n",
    "    bijoy_text = uc.convert_unicode_to_bijoy(unicode_text)\n",
    "    return bijoy_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "id": "bf0195bb-b283-4f1c-a540-d17653a616e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import docx\n",
    "from reportlab.pdfgen import canvas\n",
    "from reportlab.lib.pagesizes import letter\n",
    "import langid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "id": "9b521d1a-ef23-4334-b1a9-375347dcb200",
   "metadata": {},
   "outputs": [],
   "source": [
    "from reportlab.pdfgen import canvas\n",
    "from reportlab.lib.pagesizes import letter\n",
    "import docx\n",
    "import langid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "id": "6dc8bcf3-130a-4b08-92e0-3241e4354abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading The Doc File Using Python Docx Library\n",
    "doc_file_path = r'C:\\Users\\minha\\Downloads\\Project eBook Automation\\Project eBook Automation\\Ebook\\Test_book_1.docx' #you have to pass your ebook location\n",
    "original_doc = docx.Document(doc_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "id": "4f71e00b-722c-4fba-9e2e-ac7d0895dd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "header = original_doc.paragraphs[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "id": "383c9356-82f1-4b05-9e92-9aacad80c40c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'Bmjv‡gi mykxZj QvqvZ‡j Avkªq MÖnYKvix fviZxq bIgymwjg‡`i †ivgvÂKi mv¶vrKvi',\n",
       "  'bold': True,\n",
       "  'font_size': 16.0},\n",
       " {'text': 'gw›`i †_‡K gmwR‡`', 'bold': True, 'font_size': 36.0},\n",
       " {'text': '[cÖ_g LÊ]', 'bold': True, 'font_size': 18.0},\n",
       " {'text': '', 'bold': True, 'font_size': 19.0},\n",
       " {'text': 'wb‡`©kbv', 'bold': True, 'font_size': 16.0},\n",
       " {'text': 'nhiZ gvIjvbv gynv¤§` Kvjxg wmÏxwK',\n",
       "  'bold': True,\n",
       "  'font_size': 18.0},\n",
       " {'text': 'Dc‡`óv gvwmK AvigyMvb Ges cwiPvjK',\n",
       "  'bold': False,\n",
       "  'font_size': 13.0},\n",
       " {'text': 'RvwgAvZzj Bgvg IwjDjvn Avj Bmjvwgqv',\n",
       "  'bold': False,\n",
       "  'font_size': 13.0},\n",
       " {'text': 'dzjvZ, gyhvddi bMi, BD,wc, fviZ', 'bold': False, 'font_size': 13.0},\n",
       " {'text': '', 'bold': False, 'font_size': 14.0},\n",
       " {'text': 'msKjb', 'bold': True, 'font_size': 16.0},\n",
       " {'text': 'gydZx gynv¤§` iIkb kvn Kv‡mgx ', 'bold': True, 'font_size': 18.0},\n",
       " {'text': 'gnvivóª fviZ', 'bold': False, 'font_size': 13.0},\n",
       " {'text': 'Abyev` I m¤úv`bv', 'bold': True, 'font_size': 16.0},\n",
       " {'text': 'gydZx gxhvbyi ingvb Kv‡mgx ', 'bold': True, 'font_size': 18.0},\n",
       " {'text': 'RvwgAv ivngvwbqv Avivweqv mvZ gmwR` gv`ªvmv',\n",
       "  'bold': False,\n",
       "  'font_size': 14.0},\n",
       " {'text': 'cÖKvkbvq', 'bold': True, 'font_size': 16.0},\n",
       " {'text': '', 'bold': True, 'font_size': 16.0},\n",
       " {'text': '', 'bold': True, 'font_size': 18.0},\n",
       " {'text': 'cÖ_g cÖKvk : RyjvB 2012 Bs', 'bold': True, 'font_size': 13.0},\n",
       " {'text': 'wØZxq ms¯‹iY : A‡±vei 2012 Bs', 'bold': True, 'font_size': 13.0},\n",
       " {'text': ' Bmjv‡gi mykxZj QvqvZ‡j Avkªq MÖnYKvix fviZxq ',\n",
       "  'bold': True,\n",
       "  'font_size': 13.0},\n",
       " {'text': 'bIgymwjg‡`i †ivgvÂKi mv¶vrKvi', 'bold': True, 'font_size': 13.0},\n",
       " {'text': 'gw›`i †_‡K gmwR‡`', 'bold': True, 'font_size': 16.0},\n",
       " {'text': 'wb‡`©kbv  nhiZ gvIjvbv gynv¤§` Kvjxg wmÏxwK',\n",
       "  'bold': True,\n",
       "  'font_size': 13.0},\n",
       " {'text': 'msKjb  gydZx gynv¤§` iIkb kvn Kv‡mgx ',\n",
       "  'bold': True,\n",
       "  'font_size': 13.0},\n",
       " {'text': 'Abyev` I m¤úv`bv  gydZx gxhvbyi ingvb Kv‡mgx ',\n",
       "  'bold': True,\n",
       "  'font_size': 13.0},\n",
       " {'text': 'cÖKvkK  bRi“j Bmjvg', 'bold': True, 'font_size': 13.0},\n",
       " {'text': '¯^Z¡  cÖKvkK KZ©„K msiw¶Z', 'bold': True, 'font_size': 13.0},\n",
       " {'text': '', 'bold': True, 'font_size': 3.0},\n",
       " {'text': 'Abyev`‡Ki K_v', 'bold': True, 'font_size': 16.0},\n",
       " {'text': 'Avjnvg`ywjjvn! iIkb kvn Kv‡mgx mv‡ne cwÎKvq cÖKvwkZ †mme mv¶vZKvi AviI myweb¨¯— K‡i Zv‡K wKZvex AvK…wZ w`‡q cÖKvk Kivi mye¨e¯’v K‡i‡Qb| hv Òbvmx‡g †n`vqvZ‡K †Svb‡KÓ bv‡g cuvP L‡Ê cÖKvwkZ n‡q‡Q|  Avgiv D`y© wKZv‡ei evsjv  Abyev` Ògw›`i †_‡K gmwR‡`Ó bvg w`‡q cvVK‡`i nv‡Z Zz‡j w`‡Z †c‡i Avjvn cv‡Ki `iev‡i ïKwiqv Av`vq KiwQ| Avkv Kwi D`y©fvlx cvVK‡`i gZ evsjv fvlvfvwl cvVKivI Gi Øviv DcK…Z n‡eb| Avjvn iveŸyj Avjvgxb Avgv‡`i GB †gnbZ‡K Keyj Ki“b| Avgxb|',\n",
       "  'bold': False,\n",
       "  'font_size': 13.0},\n",
       " {'text': '', 'bold': False, 'font_size': 13.0},\n",
       " {'text': 'Ñgxhvbyi ingvb Kv‡mgx ', 'bold': True, 'font_size': 13.0},\n",
       " {'text': 'Rvwgqv ivngvwbqv mvZ gmwR` gv`ªvmv',\n",
       "  'bold': False,\n",
       "  'font_size': 13.0},\n",
       " {'text': '', 'bold': True, 'font_size': 15.0}]"
      ]
     },
     "execution_count": 645,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from reportlab.pdfgen import canvas\n",
    "from reportlab.pdfbase import pdfmetrics\n",
    "from reportlab.pdfbase.ttfonts import TTFont\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from docx import Document\n",
    "import unicodedata\n",
    "import re\n",
    "\n",
    "pdfmetrics.registerFont(TTFont('SutonnyMJ', r'C:\\Users\\minha\\Downloads\\sutonnymj-regular\\SutonnyMJ Regular\\SutonnyMJ Regular.ttf'))\n",
    "pdfmetrics.registerFont(TTFont('AlMajid-Quranic', r'C:\\Users\\minha\\Downloads\\al-majeed-quranic-font-regular\\Al Majeed Quranic Font Regular\\Al Majeed Quranic Font Regular.ttf'))\n",
    "\n",
    "def get_prediction(input_text):\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    outputs = model(**inputs)\n",
    "    predictions = torch.argmax(outputs.logits, dim=1)\n",
    "    if predictions.item() == 0:\n",
    "        return \"Unnecessary Text\"\n",
    "    elif predictions.item() == 2:\n",
    "        return \"Index\"\n",
    "    else:\n",
    "        return \"Necessary Text\"\n",
    "\n",
    "\n",
    "def is_url(word):\n",
    "    url_pattern = r'\\b(?:https?|ftp)?(?::\\/\\/)?(?:www\\.)?[a-zA-Z0-9-]+\\.[a-zA-Z]{2,}(?:\\/[^\\s]*)?\\b'\n",
    "    return bool(re.match(url_pattern, word))\n",
    "\n",
    "\n",
    "body_index = 0\n",
    "header_paragraphs=[]\n",
    "for index,paragraph in enumerate(header):\n",
    "    text = paragraph.text\n",
    "    converted_text = unicoded_text(text)\n",
    "    prediction = get_prediction(converted_text)\n",
    "    if converted_text in ['সূচি','সূচিপত্র',\"index\"]:\n",
    "        body_index = index \n",
    "        break\n",
    "    if prediction == \"Unnecessary Text\" or is_url(converted_text):\n",
    "        continue\n",
    "    else:\n",
    "        font_weight = 'bold' if any(run.bold for run in paragraph.runs) else 'normal'\n",
    "        font_size = next((run.font.size for run in paragraph.runs if run.font.size), None)\n",
    "        if font_size:\n",
    "            font_size = Pt(font_size / 12700).pt\n",
    "        header_paragraphs.append({\n",
    "            'text': text,\n",
    "            'bold': font_weight == 'bold',\n",
    "            'font_size': font_size\n",
    "        })\n",
    "        \n",
    "after_duplicate_removal = []\n",
    "seen = set()\n",
    "for d in header_paragraphs:\n",
    "    dict_tuple = tuple(sorted(d.items()))\n",
    "    if dict_tuple not in seen:\n",
    "        seen.add(dict_tuple)\n",
    "        after_duplicate_removal.append(d)\n",
    "after_duplicate_removal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "id": "2ef7e87b-f880-4224-9f97-b510ad17e880",
   "metadata": {},
   "outputs": [],
   "source": [
    "from docx import Document\n",
    "from docx.enum.text import WD_PARAGRAPH_ALIGNMENT\n",
    "from docx.enum.section import WD_SECTION\n",
    "from docx.enum.section import WD_ORIENT\n",
    "from docx.shared import Pt, Inches\n",
    "from docx.enum.section import WD_SECTION_START\n",
    "from docx.oxml import OxmlElement\n",
    "import langid\n",
    "\n",
    "doc = Document()\n",
    "sections = doc.sections\n",
    "for section in sections:\n",
    "    section.top_margin = Inches(1)\n",
    "    section.bottom_margin = Inches(1)\n",
    "    section.left_margin = Inches(1)\n",
    "    section.right_margin = Inches(1)\n",
    "\n",
    "    section.vertical_alignment =WD_PARAGRAPH_ALIGNMENT.CENTER\n",
    "\n",
    "for item in after_duplicate_removal:\n",
    "    paragraph = doc.add_paragraph()\n",
    "    run = paragraph.add_run(item['text'])\n",
    "    run.bold = item['bold']\n",
    "    \n",
    "    if item['font_size']:\n",
    "        run.font.size = Pt(item['font_size'])\n",
    "    paragraph.alignment = WD_PARAGRAPH_ALIGNMENT.CENTER\n",
    "\n",
    "body_section = original_doc.paragraphs[body_index:]\n",
    "body_paragraphs=[]\n",
    "\n",
    "for index,paragraph in enumerate(body_section):\n",
    "    text = paragraph.text\n",
    "    if is_url(text):\n",
    "        continue\n",
    "    font_weight = 'bold' if any(run.bold for run in paragraph.runs) else 'normal'\n",
    "    font_size = next((run.font.size for run in paragraph.runs if run.font.size), None)\n",
    "    if font_size:\n",
    "        font_size = Pt(font_size / 12700).pt\n",
    "    body_paragraphs.append({\n",
    "        'text': text,\n",
    "        'bold': font_weight == 'bold',\n",
    "        'font_size': font_size\n",
    "    })\n",
    "\n",
    "for item in body_paragraphs:\n",
    "    paragraph = doc.add_paragraph()\n",
    "    run = paragraph.add_run(item['text'])\n",
    "    \n",
    "    if item['font_size']:\n",
    "        run.font.size = Pt(item['font_size'])\n",
    "    paragraph.alignment = WD_PARAGRAPH_ALIGNMENT.JUSTIFY\n",
    "\n",
    "def set_font(run, font_name='SutonnyMJ'):\n",
    "    run.font.name = font_name\n",
    "    r = run._r\n",
    "    rPr = r.get_or_add_rPr()\n",
    "    rFonts = OxmlElement('w:rFonts')\n",
    "    rFonts.set(qn('w:ascii'), font_name)\n",
    "    rFonts.set(qn('w:eastAsia'), font_name)\n",
    "    rPr.append(rFonts)\n",
    "\n",
    "for paragraph in doc.paragraphs:\n",
    "    text = unicoded_text(paragraph.text)\n",
    "    lang, confidence = langid.classify(text)\n",
    "    if lang == \"bn\" or lang ==\"as\":\n",
    "        for run in paragraph.runs:\n",
    "            set_font(run, 'SutonnyMJ')\n",
    "    if lang == \"en\":\n",
    "        for run in paragraph.runs:\n",
    "            set_font(run, 'Times New Roman')\n",
    "    if lang == \"ar\" or lang == \"fs\":\n",
    "        for run in paragraph.runs:\n",
    "            set_font(run, 'Al Majeed Quranic')\n",
    "\n",
    "doc.save(r'E:\\Corrected Text 2.docx')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
