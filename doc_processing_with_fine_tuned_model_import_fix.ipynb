{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "323d0dd6-5110-4224-bfab-345f95bc321a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch #may take some times\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8e8da551-e5f5-4236-9a70-316df9530a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"./fine_tuned_bengali_model\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./fine_tuned_bengali_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2b3c33c2-82c4-46a4-9673-331eecae4145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 1\n"
     ]
    }
   ],
   "source": [
    "input_text = \"১ম প্রকাশ\"\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "outputs = model(**inputs)\n",
    "predictions = torch.argmax(outputs.logits, dim=1)\n",
    "print(f\"Prediction: {predictions.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "633d8ecb-136f-41dc-a33b-40029868b6c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-docx in c:\\users\\minha\\anaconda3\\lib\\site-packages (1.1.2)\n",
      "Requirement already satisfied: lxml>=3.1.0 in c:\\users\\minha\\anaconda3\\lib\\site-packages (from python-docx) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=4.9.0 in c:\\users\\minha\\anaconda3\\lib\\site-packages (from python-docx) (4.11.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install python-docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "473a727e-6c38-4ed0-af7a-cd0e00519b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: unicodeconverter in c:\\users\\minha\\anaconda3\\lib\\site-packages (0.1.0b12)\n"
     ]
    }
   ],
   "source": [
    "!pip install unicodeconverter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "70663faf-9447-4f0e-ae96-d86070aec3a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langid in c:\\users\\minha\\anaconda3\\lib\\site-packages (1.1.6)\n",
      "Requirement already satisfied: numpy in c:\\users\\minha\\anaconda3\\lib\\site-packages (from langid) (1.26.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install langid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "50293bdb-a7d5-4747-a032-3aadb70654d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodeconverter as uc\n",
    "import docx\n",
    "def unicoded_text(bijoy_text):\n",
    "  unicode_text = uc.convert_bijoy_to_unicode(bijoy_text)\n",
    "  return unicode_text\n",
    "\n",
    "def reverse_unicode(unicode_text):\n",
    "    bijoy_text = uc.convert_unicode_to_bijoy(unicode_text)\n",
    "    return bijoy_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6dc8bcf3-130a-4b08-92e0-3241e4354abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading The Doc File Using Python Docx Library\n",
    "doc_file_path = r'C:\\Users\\minha\\Downloads\\Project eBook Automation\\Project eBook Automation\\Ebook\\416455.docx' #you have to pass your ebook location\n",
    "original_doc = docx.Document(doc_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4f71e00b-722c-4fba-9e2e-ac7d0895dd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "header = original_doc.paragraphs[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "383c9356-82f1-4b05-9e92-9aacad80c40c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': '', 'bold': True, 'font_size': 12.5},\n",
       " {'text': '', 'bold': False, 'font_size': None},\n",
       " {'text': '', 'bold': False, 'font_size': 12.5},\n",
       " {'text': 'হেলেন হ্যানফ্', 'bold': True, 'font_size': 14.0},\n",
       " {'text': 'ভাষান্তর: ', 'bold': False, 'font_size': 12.0},\n",
       " {'text': 'তানজীম', 'bold': True, 'font_size': 12.0},\n",
       " {'text': 'ফারহানা জাহান', 'bold': True, 'font_size': 12.0},\n",
       " {'text': ' ', 'bold': False, 'font_size': 12.0},\n",
       " {'text': 'অনুবাদকের উৎসর্গ ', 'bold': True, 'font_size': 18.0},\n",
       " {'text': 'ফারহানা জাহান', 'bold': False, 'font_size': 13.0},\n",
       " {'text': 'তানজীম', 'bold': False, 'font_size': 13.0},\n",
       " {'text': 'মুখবন্ধ', 'bold': True, 'font_size': 20.0},\n",
       " {'text': 'অ্যান ব্যানক্রফট', 'bold': True, 'font_size': 13.0},\n",
       " {'text': ' অক্টোবর ৫, ১৯৪৯', 'bold': False, 'font_size': 13.0},\n",
       " {'text': 'ইংল্যান্ড।', 'bold': False, 'font_size': 13.0},\n",
       " {'text': 'মহোদয়বৃন্দ, ', 'bold': False, 'font_size': 13.0},\n",
       " {'text': 'বিনীতা', 'bold': False, 'font_size': 13.0},\n",
       " {'text': 'হেলেন হ্যানফ্', 'bold': False, 'font_size': 13.0},\n",
       " {'text': '(মিস) হেলেন হ্যানফ্', 'bold': False, 'font_size': 13.0},\n",
       " {'text': '২৫ অক্টোবর, ১৯৪৯', 'bold': False, 'font_size': 13.0},\n",
       " {'text': 'মিস হেলেন হ্যানফ্,', 'bold': False, 'font_size': 13.0},\n",
       " {'text': '১৪ ইস্ট, নাইন্টি-ফিফথ স্ট্রিট', 'bold': False, 'font_size': 13.0},\n",
       " {'text': 'যুক্তরাষ্ট্র।', 'bold': False, 'font_size': 13.0},\n",
       " {'text': 'ডিয়ার ম্যাডাম,', 'bold': False, 'font_size': 13.0},\n",
       " {'text': 'বিনীত', 'bold': False, 'font_size': 13.0},\n",
       " {'text': 'এফপিডি', 'bold': False, 'font_size': 13.0},\n",
       " {'text': '', 'bold': False, 'font_size': 13.0},\n",
       " {'text': ' নভেম্বর ৩, ১৯৪৯', 'bold': False, 'font_size': 13.0},\n",
       " {'text': 'ইংল্যান্ড।  ', 'bold': False, 'font_size': 13.0},\n",
       " {'text': '৯ নভেম্বর, ১৯৪৯', 'bold': False, 'font_size': 13.0},\n",
       " {'text': 'ডিয়ার মিস হ্যানফ্,', 'bold': False, 'font_size': 13.0},\n",
       " {'text': '', 'bold': True, 'font_size': 13.0},\n",
       " {'text': 'নভেম্বর ১৮, ১৯৪৯', 'bold': False, 'font_size': 13.0},\n",
       " {'text': '২৬ নভেম্বর, ১৯৪৯', 'bold': False, 'font_size': 13.0},\n",
       " {'text': 'ডিসেম্বর ৮, ১৯৪৯', 'bold': False, 'font_size': 13.0},\n",
       " {'text': 'জনাব,', 'bold': False, 'font_size': 13.0},\n",
       " {'text': '  \\t ক্রিসমাসের শুভকামনা।', 'bold': False, 'font_size': 13.0},\n",
       " {'text': 'ডিসেম্বর ৯, ১৯৪৯', 'bold': False, 'font_size': 13.0},\n",
       " {'text': 'দ্রুত পরামর্শ জানাবেন!', 'bold': False, 'font_size': 13.0},\n",
       " {'text': '২০ ডিসেম্বর, ১৯৪৯', 'bold': False, 'font_size': 13.0},\n",
       " {'text': 'ফ্র্যাঙ্ক ডোয়েল', 'bold': False, 'font_size': 13.0},\n",
       " {'text': 'মার্চ ২৫, ১৯৫০', 'bold': False, 'font_size': 13.0},\n",
       " {'text': 'এইচ এইচ', 'bold': False, 'font_size': 13.0},\n",
       " {'text': '৭ এপ্রিল, ১৯৫০', 'bold': False, 'font_size': 13.0},\n",
       " {'text': 'পার্সেলের জন্য আপনাকে ফের ধন্যবাদ।',\n",
       "  'bold': False,\n",
       "  'font_size': 13.0},\n",
       " {'text': '\\t', 'bold': False, 'font_size': 8.0},\n",
       " {'text': 'শুভকামনা রইল আপনার জন্য।', 'bold': False, 'font_size': 13.0},\n",
       " {'text': 'সেসিলি ফার', 'bold': False, 'font_size': 13.0},\n",
       " {'text': 'সি.এফ.', 'bold': False, 'font_size': 13.0},\n",
       " {'text': 'এপ্রিল ১০, ১৯৫০', 'bold': False, 'font_size': 13.0},\n",
       " {'text': 'প্রিয় সেসিলি, ', 'bold': False, 'font_size': 13.0},\n",
       " {'text': '“তবে সেখানেই তাকে পাবে।”', 'bold': False, 'font_size': 13.0},\n",
       " {'text': 'ইতি,', 'bold': False, 'font_size': 13.0},\n",
       " {'text': '২০ সেপ্টেম্বর, ১৯৫০', 'bold': False, 'font_size': 13.0},\n",
       " {'text': 'নিউম্যান (জন হেনরি, ডি.ডি.)', 'bold': False, 'font_size': 13.0},\n",
       " {'text': 'বিশ্ববিদ্যালয়ের শিক্ষাব্যবস্থার সুযোগ ও প্রকৃতি বিষয়ক বক্তৃতাসমূহ',\n",
       "  'bold': False,\n",
       "  'font_size': 13.0},\n",
       " {'text': '\\t', 'bold': False, 'font_size': 13.0},\n",
       " {'text': 'শুভেচ্ছান্তে,', 'bold': False, 'font_size': 13.0},\n",
       " {'text': 'সেপ্টেম্বর ২৫, ১৯৫০', 'bold': False, 'font_size': 13.0},\n",
       " {'text': '\\t\\t', 'bold': False, 'font_size': 13.0},\n",
       " {'text': 'সুধী ফ্র্যাঙ্ক, ', 'bold': False, 'font_size': 13.0},\n",
       " {'text': '২ অক্টোবর, ১৯৫০', 'bold': False, 'font_size': 13.0},\n",
       " {'text': 'ডিয়ার হেলেন,', 'bold': False, 'font_size': 13.0},\n",
       " {'text': 'সেসিলি', 'bold': False, 'font_size': 13.0},\n",
       " {'text': 'অক্টোবর ১৫, ১৯৫০', 'bold': False, 'font_size': 13.0},\n",
       " {'text': 'আচ্ছা!', 'bold': False, 'font_size': 13.0},\n",
       " {'text': '১ নভেম্বর, ১৯৫০', 'bold': False, 'font_size': 13.0},\n",
       " {'text': 'এফ. ডোয়েল', 'bold': False, 'font_size': 13.0},\n",
       " {'text': 'ইস্টকোট', 'bold': False, 'font_size': 13.0},\n",
       " {'text': 'পিনার', 'bold': False, 'font_size': 13.0},\n",
       " {'text': 'মিডলসেক্স', 'bold': False, 'font_size': 13.0},\n",
       " {'text': '২০-২-৫১', 'bold': False, 'font_size': 13.0},\n",
       " {'text': 'প্রিয় হেলেন,', 'bold': False, 'font_size': 13.0},\n",
       " {'text': 'সেসিলি', 'bold': True, 'font_size': 13.0},\n",
       " {'text': 'প্রিয় সেসিলি,', 'bold': False, 'font_size': 13.0},\n",
       " {'text': '\\tইতি,', 'bold': False, 'font_size': 13.0},\n",
       " {'text': 'হেলেন', 'bold': False, 'font_size': 13.0},\n",
       " {'text': '৪ এপ্রিল, ১৯৫১', 'bold': False, 'font_size': 13.0},\n",
       " {'text': 'এহ হে, বেন মার্কস একগাদা কাজ নিয়ে মাথার ওপর দাঁড়িয়ে আছেন। আজ তাহলে ক্ষান্ত দিলাম। ',\n",
       "  'bold': False,\n",
       "  'font_size': 13.0},\n",
       " {'text': 'ভালোবাসা নিও।', 'bold': False, 'font_size': 13.0},\n",
       " {'text': '৫ এপ্রিল, ১৯৫১', 'bold': False, 'font_size': 13.0},\n",
       " {'text': 'আন্তরিক শুভেচ্ছাসহ,', 'bold': False, 'font_size': 13.0},\n",
       " {'text': 'মেগান ওয়েলস।', 'bold': False, 'font_size': 13.0},\n",
       " {'text': 'টানব্রিজ রোড', 'bold': False, 'font_size': 13.0},\n",
       " {'text': 'সাউথএন্ড-অন-সী', 'bold': False, 'font_size': 13.0},\n",
       " {'text': 'এসেক্স', 'bold': False, 'font_size': 13.0},\n",
       " {'text': 'শ্রদ্ধাসহ,', 'bold': False, 'font_size': 13.0},\n",
       " {'text': 'বিল হামফ্রিজ।', 'bold': False, 'font_size': 13.0},\n",
       " {'text': '৯ এপ্রিল, ১৯৫১', 'bold': False, 'font_size': 13.0},\n",
       " {'text': 'এপ্রিল ১৬, ১৯৫১', 'bold': False, 'font_size': 13.0}]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from reportlab.pdfgen import canvas\n",
    "from reportlab.pdfbase import pdfmetrics\n",
    "from reportlab.pdfbase.ttfonts import TTFont\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from docx import Document\n",
    "import unicodedata\n",
    "import re\n",
    "from docx.shared import Pt\n",
    "\n",
    "pdfmetrics.registerFont(TTFont('SutonnyMJ', r'C:\\Users\\minha\\Downloads\\sutonnymj-regular\\SutonnyMJ Regular\\SutonnyMJ Regular.ttf'))\n",
    "pdfmetrics.registerFont(TTFont('AlMajid-Quranic', r'C:\\Users\\minha\\Downloads\\al-majeed-quranic-font-regular\\Al Majeed Quranic Font Regular\\Al Majeed Quranic Font Regular.ttf'))\n",
    "\n",
    "def get_prediction(input_text):\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    outputs = model(**inputs)\n",
    "    predictions = torch.argmax(outputs.logits, dim=1)\n",
    "    if predictions.item() == 0:\n",
    "        return \"Unnecessary Text\"\n",
    "    elif predictions.item() == 2:\n",
    "        return \"Index\"\n",
    "    else:\n",
    "        return \"Necessary Text\"\n",
    "\n",
    "\n",
    "def is_url(word):\n",
    "    url_pattern = r'\\b(?:https?|ftp)?(?::\\/\\/)?(?:www\\.)?[a-zA-Z0-9-]+\\.[a-zA-Z]{2,}(?:\\/[^\\s]*)?\\b'\n",
    "    return bool(re.match(url_pattern, word))\n",
    "\n",
    "\n",
    "body_index = 0\n",
    "header_paragraphs=[]\n",
    "for index,paragraph in enumerate(header):\n",
    "    text = paragraph.text\n",
    "    converted_text = unicoded_text(text)\n",
    "    prediction = get_prediction(converted_text)\n",
    "    if converted_text in ['সূচি','সূচিপত্র',\"index\"]:\n",
    "        body_index = index \n",
    "        break\n",
    "    if prediction == \"Unnecessary Text\" or is_url(converted_text):\n",
    "        continue\n",
    "    else:\n",
    "        font_weight = 'bold' if any(run.bold for run in paragraph.runs) else 'normal'\n",
    "        font_size = next((run.font.size for run in paragraph.runs if run.font.size), None)\n",
    "        if font_size:\n",
    "            font_size = Pt(font_size / 12700).pt\n",
    "        header_paragraphs.append({\n",
    "            'text': text,\n",
    "            'bold': font_weight == 'bold',\n",
    "            'font_size': font_size\n",
    "        })\n",
    "        \n",
    "after_duplicate_removal = []\n",
    "seen = set()\n",
    "for d in header_paragraphs:\n",
    "    dict_tuple = tuple(sorted(d.items()))\n",
    "    if dict_tuple not in seen:\n",
    "        seen.add(dict_tuple)\n",
    "        after_duplicate_removal.append(d)\n",
    "after_duplicate_removal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2ef7e87b-f880-4224-9f97-b510ad17e880",
   "metadata": {},
   "outputs": [],
   "source": [
    "from docx import Document\n",
    "from docx.enum.text import WD_PARAGRAPH_ALIGNMENT\n",
    "from docx.enum.section import WD_SECTION\n",
    "from docx.enum.section import WD_ORIENT\n",
    "from docx.shared import Pt, Inches\n",
    "from docx.enum.section import WD_SECTION_START\n",
    "from docx.oxml import OxmlElement\n",
    "import langid\n",
    "from docx.oxml.ns import qn\n",
    "\n",
    "doc = Document()\n",
    "sections = doc.sections\n",
    "for section in sections:\n",
    "    section.top_margin = Inches(1)\n",
    "    section.bottom_margin = Inches(1)\n",
    "    section.left_margin = Inches(1)\n",
    "    section.right_margin = Inches(1)\n",
    "\n",
    "    section.vertical_alignment =WD_PARAGRAPH_ALIGNMENT.CENTER\n",
    "\n",
    "for item in after_duplicate_removal:\n",
    "    paragraph = doc.add_paragraph()\n",
    "    run = paragraph.add_run(item['text'])\n",
    "    run.bold = item['bold']\n",
    "    \n",
    "    if item['font_size']:\n",
    "        run.font.size = Pt(item['font_size'])\n",
    "    paragraph.alignment = WD_PARAGRAPH_ALIGNMENT.CENTER\n",
    "\n",
    "body_section = original_doc.paragraphs[body_index:]\n",
    "body_paragraphs=[]\n",
    "\n",
    "for index,paragraph in enumerate(body_section):\n",
    "    text = paragraph.text\n",
    "    if is_url(text):\n",
    "        continue\n",
    "    font_weight = 'bold' if any(run.bold for run in paragraph.runs) else 'normal'\n",
    "    font_size = next((run.font.size for run in paragraph.runs if run.font.size), None)\n",
    "    if font_size:\n",
    "        font_size = Pt(font_size / 12700).pt\n",
    "    body_paragraphs.append({\n",
    "        'text': text,\n",
    "        'bold': font_weight == 'bold',\n",
    "        'font_size': font_size\n",
    "    })\n",
    "\n",
    "for item in body_paragraphs:\n",
    "    paragraph = doc.add_paragraph()\n",
    "    run = paragraph.add_run(item['text'])\n",
    "    \n",
    "    if item['font_size']:\n",
    "        run.font.size = Pt(item['font_size'])\n",
    "    paragraph.alignment = WD_PARAGRAPH_ALIGNMENT.JUSTIFY\n",
    "\n",
    "def set_font(run, font_name='SutonnyMJ'):\n",
    "    run.font.name = font_name\n",
    "    r = run._r\n",
    "    rPr = r.get_or_add_rPr()\n",
    "    rFonts = OxmlElement('w:rFonts')\n",
    "    rFonts.set(qn('w:ascii'), font_name)\n",
    "    rFonts.set(qn('w:eastAsia'), font_name)\n",
    "    rPr.append(rFonts)\n",
    "\n",
    "for paragraph in doc.paragraphs:\n",
    "    text = unicoded_text(paragraph.text)\n",
    "    lang, confidence = langid.classify(text)\n",
    "    if lang == \"bn\" or lang ==\"as\":\n",
    "        for run in paragraph.runs:\n",
    "            set_font(run, 'SutonnyMJ')\n",
    "    if lang == \"en\":\n",
    "        for run in paragraph.runs:\n",
    "            set_font(run, 'Times New Roman')\n",
    "    if lang == \"ar\" or lang == \"fs\":\n",
    "        for run in paragraph.runs:\n",
    "            set_font(run, 'Al Majeed Quranic')\n",
    "\n",
    "doc.save(r'E:\\Corrected Text 2.docx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ef680b-8a17-4e3f-9506-a66882ff2af0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0b4d8e-1280-434b-8ed6-5b6d4b38bb95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4035aac0-6853-4b49-b70d-e50ab9ad4007",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
